Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@techreport{Eberhardt,
abstract = {We show that if any number of variables are allowed to be simultaneously and independently randomized in any one experiment, log 2 (N) + 1 experiments are sufficient and in the worst case necessary to determine the causal relations among N ≥ 2 variables when no latent variables, no sample selection bias and no feedback cycles are present. For all K, 0 {\textless} K {\textless} 1 2 N we provide an upper bound on the number experiments required to determine causal structure when each experiment simultaneously randomizes K variables. For large N , these bounds are significantly lower than the N − 1 bound required when each experiment randomizes at most one variable. For k max {\textless} N 2 , we show that (N kmax −1)+ N 2kmax log 2 (k max) experiments are sufficient and in the worst case necessary. We offer a conjecture as to the minimal number of experiments that are in the worst case sufficient to identify all causal relations among N observed variables that are a subset of the vertices of a DAG.},
author = {Eberhardt, Frederick and Glymour, Clark and Scheines, Richard},
title = {{On the Number of Experiments Sufficient and in the Worst Case Necessary to Identify All Causal Relations Among N Variables}},
url = {http://www.its.caltech.edu/{~}fehardt/papers/EGS{\_}UAI2005.pdf}
}
@misc{Mannino2015,
abstract = {A profusion of recent work in cognitive neuroscience has been concerned with the endeavor to uncover causal influences in large-scale brain networks. However, despite the fact that many papers give a nod to the important theoretical challenges posed by the concept of causality, this explosion of research has generally not been accompanied by a rigorous conceptual analysis of the nature of causality in the brain. This review provides both a descriptive and prescriptive account of the nature of causality as found within and between large-scale brain networks. In short, it seeks to clarify the concept of causality in large-scale brain networks both philosophically and scientifically. This is accomplished by briefly reviewing the rich philosophical history of work on causality, especially focusing on contributions by David Hume, Immanuel Kant, Bertrand Russell, and Christopher Hitchcock. We go on to discuss the impact that various interpretations of modern physics have had on our understanding of causality. Throughout all this, a central focus is the distinction between theories of deterministic causality (DC), whereby causes uniquely determine their effects, and probabilistic causality (PC), whereby causes change the probability of occurrence of their effects. We argue that, given the topological complexity of its large-scale connectivity, the brain should be considered as a complex system and its causal influences treated as probabilistic in nature. We conclude that PC is well suited for explaining causality in the brain for three reasons: (1) brain causality is often mutual; (2) connectional convergence dictates that only rarely is the activity of one neuronal population uniquely determined by another one; and (3) the causal influences exerted between neuronal populations may not have observable effects. A number of different techniques are currently available to characterize causal influence in the brain. Typically, these techniques quantify the statistical likelihood that a change in the activity of one neuronal population affects the activity in another. We argue that these measures access the inherently probabilistic nature of causal influences in the brain, and are thus better suited for large-scale brain network analysis than are DC-based measures. Our work is consistent with recent advances in the philosophical study of probabilistic causality, which originated from inherent conceptual problems with deterministic regularity theories. It also resonates with concepts of stochasticity that were involved in establishing modern physics. In summary, we argue that probabilistic causality is a conceptually appropriate foundation for describing neural causality in the brain.},
author = {Mannino, Michael and Bressler, Steven L.},
booktitle = {Physics of Life Reviews},
doi = {10.1016/j.plrev.2015.09.002},
issn = {15710645},
keywords = {Brain,Brain connectivity,Causality,Determinism,Large-scale neurocognitive networks,Probability},
month = {dec},
pages = {107--123},
publisher = {Elsevier},
title = {{Foundational perspectives on causality in large-scale brain networks}},
volume = {15},
year = {2015}
}
@article{Lansdell2019,
abstract = {Neural plasticity can be seen as ultimately aiming at the maximization of reward. However, the world is complicated and nonlinear and so are neurons' firing properties. A neuron learning to make changes that lead to the maximization of reward is an estimation problem: would there be more reward if the neural activity had been different? Statistically, this is a causal inference problem. Here we show how the spiking discontinuity of neurons can be a tool to estimate the causal influence of a neuron's activity on reward. We show how it can be used to derive a novel learning rule that can operate in the presence of non-linearities and the confounding influence of other neurons. We establish a link between simple learning rules and an existing causal inference method from econometrics, yielding proofs of both the correctness of the approach as well as its asymptotic behavior.},
author = {Lansdell, Benjamin James and Kording, Konrad Paul},
doi = {10.1101/253351},
journal = {bioRxiv},
month = {feb},
pages = {253351},
publisher = {Cold Spring Harbor Laboratory},
title = {{Spiking allows neurons to estimate their causal effect}},
url = {https://www.biorxiv.org/content/10.1101/253351v4},
year = {2019}
}
@article{Stroh2012,
abstract = {{\textless}p{\textgreater}The causal analysis of neuronal network function requires selective manipulations of ge­netically defined neuronal subpopulations in the intact living brain. Here, we highlight the method of optogenetics, which meets those needs. We cover methodological aspects, limitations, and practical applications in the field of neurosciences. The fundamentals of optogenetics are light-sensitive transmembrane channels and light-driven ion pumps, which can be genetically encoded, without requir­ing the application of exogenous cofactors. These opsins are expressed in neurons by means of viral gene transfer and cell-specific promoters. Light for stimulation can be non- or minimally invasively delivered by optical fibers. Illumination of opsins results in a depo­larization or hyperpolarization of genetical­ly modified neurons, depending on the type of optogenetic actuator. Strong expression levels and sufficient light densities provided, neuronal activity can be optically controlled in the intact network with millisecond precision. By applying fluorescent indicators of neuronal activity, an all-optical neurophysiological approach becomes reality.{\textless}/p{\textgreater}},
author = {Stroh, A. and Diester, I.},
doi = {10.1007/s13295-012-0035-8},
issn = {1868-856X},
journal = {e-Neuroforum},
month = {jan},
number = {4},
pages = {81--88},
publisher = {Spektrum Akademischer Verlag},
title = {{Optogenetics: a new method for the causal analysis of neuronal networks in vivo}},
url = {http://www.degruyter.com/view/j/nf.2012.18.issue-4/s13295-012-0035-8/s13295-012-0035-8.xml},
volume = {18},
year = {2012}
}
@article{Magloire2018,
abstract = {Seizures are complex pathological network events characterized by excessive and hypersynchronized activity of neurons, including a highly diverse population of GABAergic interneurons. Although the ...},
author = {Magloire, Vincent and Mercier, Marion S. and Kullmann, Dimitri M. and Pavlov, Ivan},
doi = {10.1177/1073858418805002},
issn = {1073-8584},
journal = {The Neuroscientist},
keywords = {epilepsy,interictal spikes,interneurons,optogenetics,seizures},
month = {oct},
pages = {107385841880500},
publisher = {SAGE PublicationsSage CA: Los Angeles, CA},
title = {{GABAergic Interneurons in Seizures: Investigating Causality With Optogenetics}},
url = {http://journals.sagepub.com/doi/10.1177/1073858418805002},
year = {2018}
}
@article{Shimizu2014,
author = {Shimizu, Shohei},
doi = {10.2333/bhmk.41.65},
issn = {0385-7417},
journal = {Behaviormetrika},
keywords = {Causal inference,Causal structure learning,Estimation of causal directions,Gaussianity,Structural equation models,non},
number = {1},
pages = {65--98},
publisher = {The Behaviormetric Society},
title = {{LINGAM: NON-GAUSSIAN METHODS FOR ESTIMATING CAUSAL STRUCTURES}},
url = {http://jlc.jst.go.jp/DN/JST.JSTAGE/bhmk/41.65?lang=en{\&}from=CrossRef{\&}type=abstract},
volume = {41},
year = {2014}
}
@techreport{Eberhardtc,
abstract = {By combining experimental interventions with search procedures for graphical causal models we show that under familiar assumptions, with perfect data, N-1 experiments suffice to determine the causal relations among N{\textgreater}2 variables when each experiment randomizes at most one variable. We show the same bound holds for adaptive learners, but does not hold for N {\textgreater} 4 when each experiment can simultaneously randomize more than one variable. This bound provides a type of ideal for the measure of success of heuristic approaches in active learning methods of causal discovery, which currently use less informative measures. Three Methods and Their Limitations Consider situations in which the aim of inquiry is to determine the causal structure of a kind of system with many variables, for example the gene regulation network of a species in a particular environment. The aim in other words is to determine for each pair X, Y of variables in a set of variables, S, whether X directly causes Y (or vice-versa), with respect to the remaining variables in S, i.e., for some assignment of values V to all the remaining variables in S, if we were to intervene to hold those variables fixed at values V while randomizing X, Y would covary with X, or vice versa. Such a system of causal relations can be represented by a directed graph, in which the variables are nodes or vertices of the graph, and X → Y indicates that X is a direct cause of Y. If there are no feedback relations among the variables, the graph is acyclic. We are concerned with the most efficient way to determine the complete structure of such a directed acyclic graph, under some simplifying assumptions. Suppose that, before collecting data, nothing is known that will provide positive or negative evidence about the influence of any of the variables on any of the others. There are several ways to obtain data and to make inferences: 1 Second affiliation: Florida Institute for Human and Machine Cognition},
author = {Eberhardt, Frederick and Glymour, Clark and Scheines, Richard},
title = {{N-1 Experiments Suffice to Determine the Causal Relations Among N Variables}},
url = {http://www.its.caltech.edu/{~}fehardt/papers/EGS{\_}draft2006.pdf}
}
@article{Fisher1971,
abstract = {Abstract This fifth edition differs from the 3rd (latest edition noted, see 18: 12) by the addition of sections on the fiducial limits of a ratio (in 4th ed.), and on configuration in three or more dimensions.(See also 13: 4964).(PsycINFO Database Record (c) 2016 APA, all rights},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Fisher, Sir Ronald A.},
doi = {10.1680/udap.2010.163},
eprint = {arXiv:1011.1669v3},
isbn = {9781467312578},
issn = {00218995},
journal = {Hafner Publishing Company},
pmid = {22081213},
title = {{The Design of Experiments II}},
url = {http://www.medicine.mcgill.ca/epidemiology/hanley/tmp/Mean-Quantile/DesignofExperimentsCh-III.pdf},
year = {1971}
}
@article{Lepperød2018,
abstract = {To study how the brain works, it is crucial to identify causal interactions between neurons, which is thought to require perturbations. However, when using optogenetics we typically perturb multiple neurons, producing a confound - any of the stimulated neurons can have affected the target. Here we show how this produces large biases, and how they can be reduced using the instrumental variable (IV) framework from econometrics. The interaction between stimulation and the absolute refractory period produces a weak, approximately random signal which can be exploited to estimate causality. When simulating integrate-and-fire neurons, we find that causal connectivity estimates from IV are better than naive techniques (R2=0.77 vs R2=0.01). The difference is important as the estimates differ when applied to experimental data from stimulated neurons with recorded spiking activity. Our IV approach is easy to implement in the context of current experimental paradigms.},
author = {Lepper{\o}d, Mikkel Elle and St{\"{o}}ber, Tristan and Hafting, Torkel and Fyhn, Marianne and Kording, Konrad Paul},
doi = {10.1101/463760},
journal = {bioRxiv},
pages = {463760},
title = {{Inferring causal connectivity from pairwise recordings and optogenetics}},
url = {http://dx.doi.org/10.1101/463760 https://www.biorxiv.org/content/early/2018/11/06/463760.full.pdf+html},
year = {2018}
}
@techreport{Eberhardta,
abstract = {We conjecture that the worst case number of experiments necessary and sufficient to discover a causal graph uniquely given its observational Markov equivalence class can be specified as a function of the largest clique in the Markov equivalence class. We provide an algorithm that computes intervention sets that we believe are optimal for the above task. The algorithm builds on insights gained from the worst case analysis in Eberhardt et al. (2005) for sequences of experiments when all possible directed acyclic graphs over N variables are considered. A simulation suggests that our conjecture is correct. We also show that a generalization of our conjecture to other classes of possible graph hypotheses cannot be given easily, and in what sense the algorithm is then no longer optimal.},
author = {Eberhardt, Frederick},
title = {{Almost Optimal Intervention Sets for Causal Discovery}},
url = {http://www.its.caltech.edu/{~}fehardt/papers/Eberhardt{\_}UAI2008.pdf}
}
@techreport{Eberhardtb,
abstract = {The literature on causal discovery has focused on interventions that involve randomly assigning values to a single variable. But such a randomized intervention is not the only possibility, nor is it always optimal. In some cases it is impossible or it would be unethical to perform such an intervention. We provide an account of "hard" and "soft" interventions, and discuss what they can contribute to causal discovery. We also describe how the choice of the optimal intervention(s) depends heavily on the particular experimental setup and the assumptions that can be made.},
author = {Eberhardt, Frederick and Scheines, Richard},
title = {{Interventions and Causal Inference}},
url = {http://www.its.caltech.edu/{~}fehardt/papers/ES{\_}draftPSA2006.pdf}
}
@article{Grosse-Wentrup2016,
abstract = {We consider the task of inferring causal relations in brain imaging data with latent confounders. Using a priori knowledge that randomized experimental conditions cannot be effects of brain activity, we derive statistical conditions that are sufficient for establishing a causal relation between two neural processes, even in the presence of latent confounders. We provide an algorithm to test these conditions on empirical data, and illustrate its performance on simulated as well as on experimentally recorded EEG data.},
author = {Grosse-Wentrup, Moritz and Janzing, Dominik and Siegel, Markus and Sch{\"{o}}lkopf, Bernhard},
doi = {10.1016/j.neuroimage.2015.10.062},
issn = {10959572},
journal = {NeuroImage},
pages = {825--833},
title = {{Identification of causal relations in neuroimaging data with latent confounders: An instrumental variable approach}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2015.10.062},
volume = {125},
year = {2016}
}
@misc{Huszar2018,
annote = {Ferenc Huszar is a Machine Learning expert. In this series of his blog, he provides a very light and visual introduction to causal inference, do-calculus, interventions, and counterfactuals. He nicely supports his explanations with graphics, simple examples, and small toy calculations.},
author = {Husz{\'{a}}r, Ferenc},
title = {{ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus}},
url = {https://www.inference.vc/untitled/},
urldate = {2019-10-02},
year = {2018}
}
@article{Pearl2009,
abstract = {This review presents empirical researcherswith recent advances in causal inference, and stresses the paradigmatic shifts that must be undertaken in moving from traditional statistical analysis to causal analysis of multivariate data. Special emphasis is placed on the assumptions that underly all causal inferences, the languages used in formulating those assumptions, the conditional nature of all causal and counterfactual claims, and the methods that have been developed for the assessment of such claims. These advances are illustrated using a general theory of causation based on the Structural Causal Model (SCM) described in Pearl (2000a), which subsumes and unifies other approaches to causation, and provides a coherent mathematical foundation for the analysis of causes and counterfactuals. In particular, the paper surveys the development of mathematical tools for inferring (from a combination of data and assumptions) answers to three types of causal queries: (1) queries about the effects of potential interventions, (also called "causal effects" or "policy evaluation") (2) queries about probabilities of counterfactuals, (including assessment of "regret," "attribution" or "causes of effects") and (3) queries about direct and indirect effects (also known as "mediation"). Finally, the paper defines the formal and conceptual relationships between the structural and potential-outcome frameworks and presents tools for a symbiotic analysis that uses the strong features of both.},
author = {Pearl, Judea},
doi = {10.1214/09-SS057},
issn = {19357516},
journal = {Statistics Surveys},
keywords = {Causal effects,Causes of effects,Confounding,Counterfactuals,Graphical methods,Mediation,Policy evaluation,Potential-outcome,Structural equationmodels},
language = {en},
pages = {96--146},
publisher = {The American Statistical Association, the Bernoulli Society, the Institute of Mathematical Statistics, and the Statistical Society of Canada},
title = {{Causal inference in statistics: An overview}},
url = {https://projecteuclid.org:443/euclid.ssu/1255440554},
volume = {3},
year = {2009}
}
@article{Steinberg2013,
abstract = {Situations in which rewards are unexpectedly obtained or withheld represent opportunities for new learning. Often, this learning includes identifying cues that predict reward availability. Unexpected rewards strongly activate midbrain dopamine neurons. This phasic signal is proposed to support learning about antecedent cues by signaling discrepancies between actual and expected outcomes, termed a reward prediction error. However, it is unknown whether dopamine neuron prediction error signaling and cue-reward learning are causally linked. To test this hypothesis, we manipulated dopamine neuron activity in rats in two behavioral procedures, associative blocking and extinction, that illustrate the essential function of prediction errors in learning. We observed that optogenetic activation of dopamine neurons concurrent with reward delivery, mimicking a prediction error, was sufficient to cause long-lasting increases in cue-elicited reward-seeking behavior. Our findings establish a causal role for temporally precise dopamine neuron signaling in cue-reward learning, bridging a critical gap between experimental evidence and influential theoretical frameworks. {\textcopyright} 2013 Nature America, Inc. All rights reserved.},
annote = {A study that shows reward prediction errors signalled by DA neurons form necessary and sufficient condition for learning associations.},
author = {Steinberg, Elizabeth E and Keiflin, Ronald and Boivin, Josiah R and Witten, Ilana B and Deisseroth, Karl and Janak, Patricia H},
doi = {10.1038/nn.3413},
issn = {15461726},
journal = {Nature Neuroscience},
month = {jul},
number = {7},
pages = {966--973},
title = {{A causal link between prediction errors, dopamine neurons and learning}},
url = {http://www.nature.com/articles/nn.3413},
volume = {16},
year = {2013}
}
@book{pearl2018book,
annote = {A really accessible introduction to Causality given by the father of Causality, Judea Pearl. Thank the editor Dana Mackenzie for making it an easy to read book.},
author = {Pearl, Judea and Mackenzie, Dana},
isbn = {9780241242643},
publisher = {Penguin Books Limited},
title = {{The Book of Why: The New Science of Cause and Effect}},
url = {https://books.google.de/books?id=EmY8DwAAQBAJ},
year = {2018}
}
@book{pearl2000causality,
annote = {With his introduction of do-calculus, Judea Pearl became the father of the predominating mathematical framework for causality today. This book contains his theorems and teachings in a mathematically very rigoous manner. It might be very heavy on somebody who is new to the material, but it is a very good reference for readers that are somewhat familiar with the causality.},
author = {Pearl, Judea},
isbn = {046509760X 9780465097609},
publisher = {Springer},
title = {{Causality: models, reasoning and inference}},
url = {http://bayes.cs.ucla.edu/BOOK-2K/},
volume = {29},
year = {2000}
}
@inproceedings{Semedo2014,
abstract = {Developments in neural recording technology are rapidly enabling the recording of populations of neurons in multiple brain areas simultaneously, as well as the identification of the types of neurons being recorded (e.g., excitatory vs. inhibitory). There is a growing need for statistical methods to study the interaction among multiple, labeled populations of neurons. Rather than attempting to identify direct interactions between neurons (where the number of interactions grows with the number of neurons squared), we propose to extract a smaller number of latent variables from each population and study how these latent variables interact. Specifically, we propose extensions to probabilistic canonical correlation analysis (pCCA) to capture the temporal structure of the latent variables, as well as to distinguish within-population dynamics from between-population interactions (termed Group Latent Auto-Regressive Analysis, gLARA). We then applied these methods to populations of neurons recorded simultaneously in visual areas V1 and V2, and found that gLARA provides a better description of the recordings than pCCA. This work provides a foundation for studying how multiple populations of neurons interact and how this interaction supports brain function.},
author = {Semedo, Jo{\~{a}}o D. and Zandvakili, Amin and Kohn, Adam and Machens, Christian K. and Yu, Byron M.},
booktitle = {Advances in Neural Information Processing Systems},
issn = {10495258},
number = {January},
pages = {2942--2950},
title = {{Extracting latent structure from multiple interacting neural populations}},
url = {https://papers.nips.cc/paper/5625-extracting-latent-structure-from-multiple-interacting-neural-populations},
volume = {4},
year = {2014}
}
@book{Peters2017,
abstract = {"The mathematization of causality is a relatively recent development, and has become increasingly important in data science and machine learning. This book offers a self-contained and concise introduction to causal models and how to learn them from data"--Back of book.},
address = {Cambridge, MA, USA},
author = {Shanmugam, Ramalingam},
booktitle = {Journal of Statistical Computation and Simulation},
doi = {10.1080/00949655.2018.1505197},
isbn = {9780262037310},
issn = {0094-9655},
number = {16},
pages = {3248--3248},
publisher = {MIT Press},
title = {{Elements of causal inference: foundations and learning algorithms}},
url = {https://mitpress.mit.edu/books/elements-causal-inference},
volume = {88},
year = {2018}
}
@article{Gershman2015,
abstract = {http://web.mit.edu/sjgershm/www/},
author = {Gershman, Samuel J},
file = {::},
journal = {Oxford Handbook of Causal Reasoning},
keywords = {goals,habits,markov decision process,structure learning},
pages = {1--32},
title = {{Reinforcement learning and causal models}},
year = {2015}
}
@phdthesis{Eberhardt2014,
abstract = {Accounts of causal discovery have traditionally split into approaches based on passive observational data and approaches based on experimental interventions that take control of (the distribution of) one or more variables. The former includes a vast number of techniques for the inference to causal structure on the basis of statistical features of data, while the latter provides in addition a methodology of how an experiment should be performed, in order to be infor-mative about causal structure. In this thesis, the causal Bayes net framework is used to integrate these two approaches and general guidelines are provided not only of how experiments should be performed but also which experiments should be performed to discover the causal structure among a potentially large number of random variables. In that sense this thesis aims to extend consid-erations found in experimental design from single experiments to sequences of experiments. To do so, the thesis provides a precise account of what constitutes an intervention that allows for, but does not necessessitate, a role of agency in interventions. We describe a space of interventions that is broader than standard randomized controlled trials, and explore what implications follow for discov-ery when different types of interventions are used. Results pertaining to the methodology of causal discovery, its limits, the efficiency of its search strategies and the meta-analysis of experimental results are presented. This thesis analy-ses the combinatorics of sequences of experiments for causal discovery, ties the discovery problem into a game-theoretic framework and points to some of the (many) difficulties that remain open research questions.},
author = {Eberhardt, Frederick},
doi = {10.1017/cbo9781139381772.004},
pages = {77--110},
title = {{Causation and Intervention}},
url = {http://www.its.caltech.edu/{~}fehardt/papers/PhDthesis.pdf},
year = {2014}
}
@misc{BroadInstitute2017,
abstract = {Machine learning expert Jonas Peters of the University of Copenhagen presents “Four Lectures on Causality”. Produced by the Laboratory for Information {\&} Decision Systems (LIDS) of MIT (https://lids.mit.edu/) and Models, Inference {\&} Algorithms of the Broad Institute (https://broadinstitute.org/mia). Most of recent machine learning is focused on pure predictive performance, which has been a driving force behind its practical success. The question of causality (understanding why predictions work) has been somewhat left behind. This paradigm is incredibly important, because it can help understand things like which genes cause which diseases, and which policy affects which economic indicator, for example. In the field of causality we want to understand how a system reacts under interventions (e.g. in gene knock-out experiments). These questions go beyond statistical dependences and can therefore not be answered by standard regression or classification techniques. In this tutorial you will learn about the interesting problem of causal inference and recent developments in the field. No prior knowledge about causality is required. Part 1: We introduce structural causal models and formalize interventional distributions. We define causal effects and show how to compute them if the causal structure is known.},
annote = {This is what got us started in the topic. This is a seminar by Jan Peters consisting of four videos that gives us a really fun, accessible introduction to Causality. He is one of the authors of Elements of Causality book that we referred to in our seminar. We are kind of biased given that his orgins are in Tuebingen :)},
author = {{Broad Institute}},
title = {{Lectures on Causality: Jonas Peters (YouTube)}},
url = {https://www.youtube.com/watch?v=zvrcyqcN9Wo{\&}feature=youtu.be https://www.youtube.com/watch?v=zvrcyqcN9Wo},
year = {2017}
}
@techreport{Venmans2016,
author = {Venmans, Frank},
file = {::},
institution = {University of Mons},
title = {{Potential outcomes and randomized experiments}},
url = {http://homepages.ulb.ac.be/{~}frycx/Slides Venmans 3.pdf},
year = {2016}
}
@article{Weichwald2015,
abstract = {Causal terminology is often introduced in the interpretation of encoding and decoding models trained on neuroimaging data. In this article, we investigate which causal statements are warranted and which ones are not supported by empirical evidence. We argue that the distinction between encoding and decoding models is not sufficient for this purpose: relevant features in encoding and decoding models carry a different meaning in stimulus- and in response-based experimental paradigms. We show that only encoding models in the stimulus-based setting support unambiguous causal interpretations. By combining encoding and decoding models trained on the same data, however, we obtain insights into causal relations beyond those that are implied by each individual model type. We illustrate the empirical relevance of our theoretical findings on EEG data recorded during a visuo-motor learning task.},
archivePrefix = {arXiv},
arxivId = {1511.04780},
author = {Weichwald, Sebastian and Meyer, Timm and {\"{O}}zdenizci, Ozan and Sch{\"{o}}lkopf, Bernhard and Ball, Tonio and Grosse-Wentrup, Moritz},
doi = {10.1016/j.neuroimage.2015.01.036},
eprint = {1511.04780},
issn = {10959572},
journal = {NeuroImage},
keywords = {Causal inference,Decoding models,Encoding models,Interpretation,Pattern recognition},
pages = {48--59},
title = {{Causal interpretation rules for encoding and decoding models in neuroimaging}},
url = {https://www.pathlms.com/ohbm/courses/1492/sections/1824/video{\_}presentations/17193},
volume = {110},
year = {2015}
}
@incollection{Campbell2010,
abstract = {Interventionist analyses make explicit the conception of causation used in experimental science, but have not been applied to the case of mental causation. This chapter addresses some of the basic problems of mental causation in interventionist terms. It proposes a way of finding the "right level" of variables to use in characterizing the causal workings of a system, whether we should be describing causal relations in psychological rather than biological terms. It argues that a notion of "soft" intervention is needed when discussing causation by reasons. Finally, we can make sense of the idea of causation without mechanisms, and we may have to do that when we are considering the outcomes of combinations of psychological and biological variables.},
author = {Campbell, John},
booktitle = {Causal Learning: Psychology, Philosophy, and Computation},
doi = {10.1093/acprof:oso/9780195176803.003.0005},
isbn = {9780199958511},
keywords = {Causation,Mental causation,Rationality,Soft intervention},
title = {{An Interventionist Approach to Causation in Psychology}},
url = {https://www.nyu.edu/gsas/dept/philo/courses/consciousness05/Campbell.pdf},
year = {2010}
}
@misc{Humphries2017,
author = {Humphries, Mark},
title = {{Some limits on interpreting causality in neuroscience experiments}},
url = {https://medium.com/the-spike/some-limits-on-interpreting-causality-in-neuroscience-experiments-f777a63650c7},
urldate = {2019-09-05},
year = {2017}
}
@article{Marinescu2018a,
abstract = {In many scientific domains, causality is the key question. For example, in neuroscience, we might ask whether a medication affects perception, cognition or action. Randomized controlled trials are the gold standard to establish causality, but they are not always practical. The field of empirical economics has developed rigorous methods to establish causality even when randomized controlled trials are not available. Here we review these quasi-experimental methods and highlight how neuroscience and behavioural researchers can use them to do research that can credibly demonstrate causal effects.},
annote = {A recent review article by Konrad Kording and Iona Marinescu that pits theoretical (Pearl style) and empirical (ecometrics-based) techniques for determining causality against one another. 

{\{}S: Konrad graciously accepted to come to Tuebingen amd give a talk on Causal Neuroscience. He even gave us his material for this workshop. Kudos to him to be such a great sport.}},
author = {Marinescu, Ioana E. and Lawlor, Patrick N. and Kording, Konrad P.},
doi = {10.1038/s41562-018-0466-5},
issn = {23973374},
journal = {Nature Human Behaviour},
month = {dec},
number = {12},
pages = {891--898},
title = {{Quasi-experimental causality in neuroscience and behavioural research}},
url = {http://www.nature.com/articles/s41562-018-0466-5},
volume = {2},
year = {2018}
}
